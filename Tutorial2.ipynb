{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TENSOR BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.empty(1) #initializing an empty tensor of size 1 like a scalar value\n",
    "print(x)\n",
    "x = torch.empty(3) #initializing an empty 1d tensor of size 3 \n",
    "print(x)\n",
    "x = torch.empty(2,3) #initializing an empty 2d tensor  \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7182])\n",
      "tensor([0.1186, 0.1046, 0.5947])\n",
      "tensor([[0.4426, 0.8791, 0.6107],\n",
      "        [0.1566, 0.7066, 0.3705]])\n"
     ]
    }
   ],
   "source": [
    "#creating tensor with random values like we used to do in numpy\n",
    "x = torch.rand(1) #initializing an tensor of size 1 like a scalar value\n",
    "print(x)\n",
    "x = torch.rand(3) #initializing an 1d tensor of size 3 \n",
    "print(x)\n",
    "x = torch.rand(2,3) #initializing an 2d tensor  \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#creating tensor with zeros or ones like we used to do in numpy\n",
    "x = torch.ones(1) #initializing an tensor of size 1 like a scalar value\n",
    "print(x)\n",
    "x = torch.zeros(3) #initializing an 1d tensor of size 3 \n",
    "print(x)\n",
    "x = torch.ones(2,3) #initializing an 2d tensor  \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int32\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,3) \n",
    "print(x.dtype)\n",
    "#giving our tensor a specific datatype\n",
    "x = torch.ones(2,3,dtype=torch.int) #similarly you can also use torch.double,torch.float16 etc \n",
    "print(x.dtype)\n",
    "#checking tensor size\n",
    "x = torch.ones(2,3,dtype=torch.int) #similarly you can also use torch.double,torch.float16 etc \n",
    "print(x.size()) #brackets needed because it is a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 5.4000])\n",
      "torch.float32\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# creating tensor from a list\n",
    "x = torch.tensor([2,5.4])\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELEMENTWISE ADDITION OF TWO TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6160, 0.0123],\n",
      "        [0.0038, 0.5647]])\n",
      "tensor([[0.6633, 0.8022],\n",
      "        [0.4367, 0.7818]])\n",
      "tensor([[1.2793, 0.8145],\n",
      "        [0.4405, 1.3465]])\n",
      "tensor([[1.2793, 0.8145],\n",
      "        [0.4405, 1.3465]])\n",
      "tensor([[1.2793, 0.8145],\n",
      "        [0.4405, 1.3465]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)\n",
    "z=x+y\n",
    "print(z)\n",
    "z=torch.add(x,y)\n",
    "print(z) \n",
    "#inplace addition\n",
    "y.add_(x)  #In pytorch every function with a trailing underscore does an inplace operation\n",
    "print(y)\n",
    "#similary you can do sub,mul,div"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLICING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6557, 0.6812, 0.6755],\n",
      "        [0.0482, 0.8066, 0.2419],\n",
      "        [0.0941, 0.3365, 0.5502],\n",
      "        [0.2944, 0.9769, 0.9492],\n",
      "        [0.0114, 0.3923, 0.1037]])\n",
      "tensor([0.6557, 0.0482, 0.0941, 0.2944, 0.0114])\n",
      "tensor([0.0482, 0.8066, 0.2419])\n",
      "tensor(0.8066)\n",
      "0.8065613508224487\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[:,0])  #all the rows only the first column\n",
    "print(x[1,:]) #2nd row and all the columns\n",
    "print(x[1,1]) #only one element\n",
    "print(x[1,1].item()) #to get the actual value of the element  when you have a tensor with only one element"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESHAPING A TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0612, 0.5988, 0.2431, 0.5597],\n",
      "        [0.3423, 0.7685, 0.6997, 0.6371],\n",
      "        [0.1870, 0.2019, 0.8904, 0.4938],\n",
      "        [0.1297, 0.8866, 0.5496, 0.6870]])\n",
      "tensor([0.0612, 0.5988, 0.2431, 0.5597, 0.3423, 0.7685, 0.6997, 0.6371, 0.1870,\n",
      "        0.2019, 0.8904, 0.4938, 0.1297, 0.8866, 0.5496, 0.6870])\n",
      "torch.Size([2, 8])\n",
      "tensor([[0.0612, 0.5988, 0.2431, 0.5597, 0.3423, 0.7685, 0.6997, 0.6371],\n",
      "        [0.1870, 0.2019, 0.8904, 0.4938, 0.1297, 0.8866, 0.5496, 0.6870]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "y = x.view(16) #we want a 1d tensor and of course the no. of elements must be the same\n",
    "print(y) \n",
    "\n",
    "y = x.view(-1,8) #in case of multiple dimensions if you don't want to specify one dimension you can write -1 ,pytorch automatically will take correct dimension\n",
    "print(y.size())\n",
    "print(y)  #2d tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERTING NUMPY TO A TORCH TENSOR AND VICE-VERSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy() #tensor to numpy array\n",
    "print(type(b))\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "b=b+1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to be carefulabout if the tensor is in cpu not in gpu then a and b will be pointing to the same memory location so if you change in a then b will get changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#numpy array to tensor\n",
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)   # you can specify datatype here by dtype = ....\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a += 1\n",
    "print(a)\n",
    "print(b) #while changing a , b will also get changed  because tensor b is in cpu and pointing to the same memory location as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "b.add_(1)\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if gpu is available or not\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING A GPU TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's assume gpu is available\n",
    "x = torch.ones(5,device=device) #Directly creating the tensor in the gpu\n",
    "y = torch.ones(5) #at first creating the tensor in cpu \n",
    "y = y.to(device) #then moving it into gpu\n",
    "z = x+y #this operation will happen in gpu and it will be much faster\n",
    "# now you have to be careful because numpy can only handle a cpu tensor not a gpu tensor \n",
    "# so to convert a gpu tensor to a numpy array at first you have convert it into a cpu tensor then convert it into a numpy array\n",
    "z.numpy() #it will give error\n",
    "z = z.to(\"cpu\")\n",
    "g = z.numpy() # now it is a valid operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5,requires_grad=True) #by default it is false\n",
    "#it will tell pytorch that when we optimize a variable that is dependent on this variable we will require the gradient w.r.t. this variable\n",
    "print(x)           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
