{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET & DATALOADER - BATCH TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nepoch = 1 forward and backward pass of all training samples\\n\\nbatch_size = number of training samples in one forward and backward pass\\n\\nnumber of iterations per epoch = number of passes, each pass using [batch_size] number of samples\\n\\ne.g. 100 samples, batch_size = 20 --> 100/20 = 5 iterations for 1 epoch\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "epoch = 1 forward and backward pass of all training samples\n",
    "\n",
    "batch_size = number of training samples in one forward and backward pass\n",
    "\n",
    "number of iterations per epoch = number of passes, each pass using [batch_size] number of samples\n",
    "\n",
    "e.g. 100 samples, batch_size = 20 --> 100/20 = 5 iterations for 1 epoch\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0       1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1       1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2       1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3       1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4       1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "..    ...      ...         ...   ...   ...  ...      ...         ...   \n",
       "173     3    13.71        5.65  2.45  20.5   95     1.68        0.61   \n",
       "174     3    13.40        3.91  2.48  23.0  102     1.80        0.75   \n",
       "175     3    13.27        4.28  2.26  20.0  120     1.59        0.69   \n",
       "176     3    13.17        2.59  2.37  20.0  120     1.65        0.68   \n",
       "177     3    14.13        4.10  2.74  24.5   96     2.05        0.76   \n",
       "\n",
       "     Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                    0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                    0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                    0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                    0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                    0.39     1.82       4.32  1.04  2.93      735  \n",
       "..                    ...      ...        ...   ...   ...      ...  \n",
       "173                  0.52     1.06       7.70  0.64  1.74      740  \n",
       "174                  0.43     1.41       7.30  0.70  1.56      750  \n",
       "175                  0.43     1.35      10.20  0.59  1.56      835  \n",
       "176                  0.53     1.46       9.30  0.60  1.62      840  \n",
       "177                  0.56     1.35       9.20  0.61  1.60      560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dv = pd.read_csv('wine.csv')\n",
    "dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "import math  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Our Own Custom Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset): #must inherit Dataset\n",
    "       def __init__(self):\n",
    "           #data loading\n",
    "           xy = np.loadtxt('wine.csv',delimiter=\",\",dtype = np.float32,skiprows=1) #delimiter = \",\" because it is a comma separated file and skiprows =1 to skip the header\n",
    "           self.x = torch.from_numpy(xy[:,1:]) #the attributes or the features ,neglecting the 0th column as it is class label\n",
    "           self.y = torch.from_numpy(xy[:,[0]]) # the ground truths ,[0] because we want the shape of y in n_samples,1 form  \n",
    "           self.n_samples = xy.shape[0]\n",
    "       def __getitem__(self,index):\n",
    "           #indexing dataset\n",
    "           #like dataet[0]\n",
    "           return self.x[index],self.y[index] #this will return a tuple\n",
    "       def __len__(self):\n",
    "           #len(dataset)\n",
    "           return self.n_samples\n",
    "       \n",
    "#creation of the dataset\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features,labels = first_data\n",
    "print(features,labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How To Use The Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2580e+01, 1.2900e+00, 2.1000e+00, 2.0000e+01, 1.0300e+02, 1.4800e+00,\n",
      "         5.8000e-01, 5.3000e-01, 1.4000e+00, 7.6000e+00, 5.8000e-01, 1.5500e+00,\n",
      "         6.4000e+02],\n",
      "        [1.3160e+01, 3.5700e+00, 2.1500e+00, 2.1000e+01, 1.0200e+02, 1.5000e+00,\n",
      "         5.5000e-01, 4.3000e-01, 1.3000e+00, 4.0000e+00, 6.0000e-01, 1.6800e+00,\n",
      "         8.3000e+02],\n",
      "        [1.2210e+01, 1.1900e+00, 1.7500e+00, 1.6800e+01, 1.5100e+02, 1.8500e+00,\n",
      "         1.2800e+00, 1.4000e-01, 2.5000e+00, 2.8500e+00, 1.2800e+00, 3.0700e+00,\n",
      "         7.1800e+02],\n",
      "        [1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "         1.0650e+03]]) tensor([[3.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "#creating a dataloader object\n",
    "dataloader = DataLoader(dataset=dataset,batch_size=4,shuffle=True) #num_workers=2 makes loading faster because it uses multiple sub processes now\n",
    "#now let's convert the dataloader object into an iterator\n",
    "dataiter = iter(dataloader)\n",
    "data = dataiter.__next__() #only getting the first batch\n",
    "#now unpack data\n",
    "features,labels = data\n",
    "print(features,labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As batch size is 4 , so we see 4 different feature vectors in our feature tensor and 4 different class labels in our labels tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4) #no. of iterations per epoch and 4 is the batch size\n",
    "print(total_samples,n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no. 1/3, iteration no. 5/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 1/3, iteration no. 10/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 1/3, iteration no. 15/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 1/3, iteration no. 20/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 1/3, iteration no. 25/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 1/3, iteration no. 30/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 1/3, iteration no. 35/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 1/3, iteration no. 40/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 1/3, iteration no. 45/45, batch shape: torch.Size([2, 13]), output shape: torch.Size([2, 1]) \n",
      "epoch no. 2/3, iteration no. 5/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 2/3, iteration no. 10/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 2/3, iteration no. 15/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 2/3, iteration no. 20/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 2/3, iteration no. 25/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 2/3, iteration no. 30/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 2/3, iteration no. 35/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 2/3, iteration no. 40/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 2/3, iteration no. 45/45, batch shape: torch.Size([2, 13]), output shape: torch.Size([2, 1]) \n",
      "epoch no. 3/3, iteration no. 5/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 3/3, iteration no. 10/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 3/3, iteration no. 15/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 3/3, iteration no. 20/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 3/3, iteration no. 25/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 3/3, iteration no. 30/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 3/3, iteration no. 35/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 3/3, iteration no. 40/45, batch shape: torch.Size([4, 13]), output shape: torch.Size([4, 1]) \n",
      "epoch no. 3/3, iteration no. 45/45, batch shape: torch.Size([2, 13]), output shape: torch.Size([2, 1]) \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # now iterate over dataloader and each iteration is perfomed on a batch\n",
    "    for i,(inputs,labels) in enumerate(dataloader):   #enumerate gives index in i and inputs and labels according to the batch size\n",
    "        #actually we gotta do forward pass, backward pass and wt. update for a batch iteration in an epoch\n",
    "        #but here we are going to perform some dummy work\n",
    "        if (i+1)%5 == 0:\n",
    "            print(f'epoch no. {epoch+1}/{num_epochs}, iteration no. {i+1}/{n_iterations}, batch shape: {inputs.shape}, output shape: {labels.shape} ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has some built-in datasets  \n",
    "torchvision.datasets.MNIST()\n",
    "Fashion-MNIST,CIFAR,COCO etc datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
